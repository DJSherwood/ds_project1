{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "surprised-exchange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2021.4.4-cp37-cp37m-manylinux2014_x86_64.whl (720 kB)\n",
      "\u001b[K     |████████████████████████████████| 720 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/gopherguy14/anaconda3/envs/xgboost/lib/python3.7/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /home/gopherguy14/anaconda3/envs/xgboost/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/gopherguy14/anaconda3/envs/xgboost/lib/python3.7/site-packages (from nltk) (4.61.0)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.6.2 regex-2021.4.4\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confused-luther",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/gopherguy14/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gopherguy14/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/gopherguy14/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sublime-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "respected-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # normalize case and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\",\" \",text.lower())\n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # lemmatize and remove stop words\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "literary-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorize', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "convinced-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continent-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ETL.etl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ordered-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.load_crash_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "assisted-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.crashes_df['Description'][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rubber-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline.fit_transform(X=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "common-theta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x329 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1154 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rotary-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879178     Entry ramp to I-29 Southbound from Waubonsie A...\n",
       "879179     Entry ramp to I-29 Northbound from Waubonsie A...\n",
       "977949     Lane blocked and left hand shoulder blocked du...\n",
       "977951     Lane blocked and right hand shoulder blocked d...\n",
       "978016     Right lane blocked due to accident on New Jers...\n",
       "                                 ...                        \n",
       "4232536                             At Market St - Accident.\n",
       "4232537      At Camino Del Rio/Mission Center Rd - Accident.\n",
       "4232538    At Glassell St/Grand Ave - Accident. in the ri...\n",
       "4232539       At CA-90/Marina Fwy/Jefferson Blvd - Accident.\n",
       "4232540                At Highland Ave/Arden Ave - Accident.\n",
       "Name: Description, Length: 799877, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.crashes_df.Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-youth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
